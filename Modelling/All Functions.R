#Dependencies
library(glmnet)
library(caret)
library(tidyverse)
library(recipes)
library(moments)
library(ParBayesianOptimization)
library(parallel)
library(fastknn)

#..................................Bagging Function...................................#
baggedModel = function(train, test, label_train, alpha.a, s_lambda.a, times, calibrate = FALSE){
  
  ############################################################################################
  # Generates a bagged (bootstrapped aggregated) elastic net model given a set of hyper parameters alpha and lambda.
  # 
  # Arguments:
  #
  # train -- a tibble containing the training data. The frame should contain only numeric values and be standardized and scaled. 
  # test -- a tibble containing the validation or test data that will be used to score the model's log loss. The frame should contain only numeric values and be standardized and scaled. 
  # label_train -- a factor ("ResultProper") corresponding to the train tibble.  
  # alpha.a -- a numeric value in [0,1] to train each elastic net model with in the bag.
  # s_lambda.a -- an integer value in {1, 2, 3, .... infinity} for subsetting the prediction matrix generated by glmnet. 
  # times -- an integer that specifies the number of bootstrap models to be created and then aggregated
  # calibrate -- a boolean: should the probabilities output by the trained model be calibrated? If TRUE, probabilities are calibrated using platt scaling. If FALSE, probabilities are left unprocessed. Default = TRUE.
  #
  #
  # Returns:
  #
  # list
  #   A list containing a tibble named "Predictions" which holds the predictions from the model on the test set, and another
  #   tibble containing variable importance scales generating during fitting.
  #
  ############################################################################################
  
  set.seed(3742301)
  samples = caret::createResample(y = label_train, times = times)
  pred = vector("list", length(samples))
  varImp = vector("list", length(samples))
  insample.pred = vector("list", length(samples))
  
  for (g in 1:length(samples)){
    
    train_temp = train[samples[[g]], ]
    train.label = label_train[samples[[g]]]
    modelX = glmnet(x = data.matrix(train_temp[, !names(train_temp) %in% c("ResultProper")]), y = train.label, family = "binomial", alpha = alpha.a, nlambda = 120, standardize = FALSE)
    s_lambda.a = case_when(s_lambda.a > length(modelX$lambda) ~ length(modelX$lambda), TRUE ~ s_lambda.a)
    
    pred[[g]] = predict(modelX, newx = data.matrix(test[, !names(test) %in% c("ResultProper")]), type = "response")[, s_lambda.a]
    insample.pred[[g]] = predict(modelX, newx = data.matrix(train_temp[, !names(train_temp) %in% c("ResultProper")]), type = "response")[, s_lambda.a]
    
    varImp[[g]] = tibble::rownames_to_column(varImp(modelX, lambda = modelX$lambda[s_lambda.a]), var = "Variable")
    colnames(varImp[[g]])[2] = paste("Overall:", g, sep = "")
    remove(modelX, train_temp, train.label)
    
  }
  
  pred = bind_cols(pred) %>%
    transmute(Predicted = rowMeans(.))
  
  insample.pred = bind_cols(insample.pred) %>%
    transmute(Predicted = rowMeans(.))
  
  varImp = varImp %>% reduce(left_join, by = "Variable") 
  
  means = varImp %>% select_if(is.numeric) %>% transmute(VariableImportance = rowMeans(.))
  
  varImp = tibble(Variable = varImp$Variable, meanImportance = means$VariableImportance)
  
  if(calibrate == TRUE){
    
    list(Predictions = platt.scale(label_train = label_train, predicted.prob.train = insample.pred, 
                                   predicted.prob.test = pred), VariableImportance = varImp)
    
  } else{
    
    list(Predictions = pred$Predicted, VariableImportance = varImp)  
    
  }
  
  
}

#..................................Platt Scaling/sigmoid........................................#
platt.scale = function(label_train, predicted.prob.train, predicted.prob.test){
  
  ############################################################################################
  # Calibrates a vector of probabilities using platt scaling.
  # 
  # Arguments:
  #
  # label_train -- a vector of labels (factors) for the training dataset
  # predicted.prob.train -- a numeric vector of probabilities generated on the training dataset 
  # predicted.prob.test -- a numeric vector of probabilities generated on the testing dataset
  #
  # Returns:
  #
  # numeric
  #   A vector of calibrated probabilities on the test set.
  #
  ############################################################################################
  
  model = glm(formula = label_train ~ ., data = predicted.prob.train, family = binomial(link = "logit"))
  
  scaled.prob = predict(model, newdata = predicted.prob.test, type = c("response"))
  
  scaled.prob
  
}


#..................................Log Loss Function....................................#

logLoss = function(scores, label){
  
  ############################################################################################
  # Computes the log loss given a set of probabilities and ground truth labels.
  # 
  # Arguments:
  #
  # scores -- a numeric vector of probabilities where the positive class is 1 and the negative class is 0. 
  # label -- a factor of W (win) or L (losses) representing the ground truth.
  # 
  #
  # Returns:
  #
  # numeric
  #  The mean log loss given the ground truth labels.
  #
  ############################################################################################
  
  if (is.factor(label)){
    u = ifelse(label ==  "W", 1,0)
  } else{
    u = label
  }
  
  tmp = data.frame(scores = scores, target = u)
  
  #In case there are probabilities of 1 or 0 predicted by the model (very unlikely unless severe overfitting)
  tmp = tmp %>% mutate(scores = ifelse(scores == 1, 0.9999999999999999999, ifelse(scores == 0 , 0.0000000000000000001, scores))) %>%
    mutate(logLoss = -(target * log(scores) + (1-target) * log(1-scores)))
  
  mean(tmp$logLoss)
}



#..................................PCA Function....................................#
addPCA_variables = function(traindata, testdata, standardize = FALSE){
  
  ############################################################################################
  # Binds PCA variables on to the training dataset (does not drop the columns used to create the PCA).
  # Does the same thing for the test set using the learned projection from the training set.
  # 
  # Arguments:
  #
  # traindata -- a tibble containing the training set. Should not contain the target variable (ResultProper) and if ResultProper is included, this variable will be removed before running the PCA. The tibble should only contain numeric values and be standardized and scaled. 
  # testdata -- a tibble containing the validation or test set. The tibble should only contain numeric values and be standardized and scaled.
  # standardize -- a boolean. If TRUE, standardizes and scales the resulting PCA components.
  #
  # Returns:
  #
  # list
  #  A list containing two tibbles corresponding to the original training and testing datasets with PCA variables included.
  #
  ############################################################################################
  
  traindata_tmp = traindata[, !names(traindata) %in% c("ResultProper")] %>% select_if(., is.numeric)
  testdata_tmp = testdata[, !names(testdata) %in% c("ResultProper")] %>% select_if(., is.numeric)
  
  pca_parameters = prcomp(traindata_tmp, center = FALSE, scale. = FALSE)
  pca_traindata = predict(pca_parameters, newdata = traindata_tmp)[,1:5] %>% as_tibble(.) 
  
  if(standardize == TRUE){
    
    pca_train.params = caret::preProcess(pca_traindata, method = c("center", "scale"))
    pca_traindata = predict(pca_train.params, newdata = pca_traindata)
    pca_newdata = predict(pca_parameters, newdata = testdata_tmp)[,1:5] %>% as_tibble(.) %>% predict(pca_train.params, newdata = .)
    
  }else{
    
    if(nrow(testdata) == 1){
      
      pca_newdata = predict(pca_parameters, newdata = testdata_tmp)[,1:5] %>% as_tibble(., rownames = "id") %>% spread(., key = "id", value = value)
      
    }else{
      
      pca_newdata = predict(pca_parameters, newdata = testdata_tmp)[,1:5] %>% as_tibble(.)
      
    }
  }
  
  
  list(train = bind_cols(traindata, pca_traindata), test = bind_cols(testdata, pca_newdata))
}

#..................................kNN Function....................................#
addKNN_variables = function(traindata, testdata, include_PCA = FALSE, distances = TRUE, useOnlyVariables =  NULL){
  
  ############################################################################################
  # Binds kNN variables to the dataset (does not delete the original variables used to create them)
  # Returns cumulative euclidian distances (sum of euclidian distances) to the k most closest neighbours for each class label to an observation, by default.
  # 
  # Arguments:
  #
  # traindata -- a tibble containing the training set. Should not contain the target variable (ResultProper) and if ResultProper is included, this variable will be removed before running the PCA. The tibble should only contain numeric values and be standardized and scaled. 
  # testdata -- a tibble containing the validation or test set. The tibble should only contain numeric values and be standardized and scaled.
  # include_PCA -- a boolean. If TRUE, includes any PCA components (see function addPCA_variables) in the creation of the kNN variables. Default = FALSE. The PCA variables should start with the prefix "PC".
  # distances -- a boolean. If TRUE, will return cumulative euclidian distances to the k most closest neighbours for each class label to an observation. If FALSE, calculates the proportion of winners (and therefore, losers) out of the k most closest neighbours to an observation.
  # useOnlyVariables -- a character vector that specifies which variables to use in traindata to compute kNN distances for. By default, uses all variables in traindata.
  #
  # Returns:
  #
  # list
  #  A list containing two tibbles corresponding to the original training and testing datasets with kNN variables included.
  #
  ############################################################################################
  
  if(!is.null(useOnlyVariables)){
    
    traindata_tmp = traindata %>% select(., useOnlyVariables)
    testdata_tmp = testdata %>% select(., useOnlyVariables)
    
  }
  
  if(include_PCA == TRUE){
    
    traindata_tmp = traindata %>% select_if(., is.numeric)
    testdata_tmp = testdata %>% select_if(., is.numeric)
    
  }else{
    
    traindata_tmp = traindata %>% select_if(., is.numeric) %>% as_tibble(.) %>% select(-starts_with("PC"))
    testdata_tmp = testdata %>% select_if(., is.numeric) %>% as_tibble(.) %>% select(-starts_with("PC"))
    
  }
  
  if (distances == TRUE){
    
    newframeswithKNN = fastknn::knnExtract(xtr = data.matrix(traindata_tmp), ytr = traindata$ResultProper, xte = data.matrix(testdata_tmp), k = 1, normalize = NULL)
    KNN_train = newframeswithKNN$new.tr %>% as_tibble(.) 
    
    KNN_train.params = caret::preProcess(KNN_train, method = c("center", "scale"))
    KNN_train = predict(KNN_train.params, newdata = KNN_train)
    
    KNN_test = newframeswithKNN$new.te %>% as_tibble(.) %>% predict(KNN_train.params, newdata = .)
    
    list(train = bind_cols(traindata, KNN_train), test = bind_cols(testdata, KNN_test))
    
  }else{
    
    KNN_train  = tibble(knn_W = fastknn(xtr = data.matrix(traindata_tmp), ytr = traindata$ResultProper, xte = data.matrix(traindata_tmp), k = 5, method = "vote", normalize = NULL)$prob[,2]) 
    
    KNN_train.params = caret::preProcess(KNN_train, method = c("center", "scale"))
    KNN_train = predict(KNN_train.params, newdata = KNN_train)
    
    KNN_test = tibble(knn_W = fastknn(xtr = data.matrix(traindata_tmp), ytr = traindata$ResultProper, xte = data.matrix(testdata_tmp), k = 5, method = "vote", normalize = NULL)$prob[,2]) %>%
      predict(KNN_train.params, newdata = .)
    
    list(train = bind_cols(traindata, KNN_train), test = bind_cols(testdata, KNN_test))
    
  }
  
}

#.......................Define recipe.............................................#

preProcess.recipe = function(trainX){
  
  ############################################################################################
  # Creates a recipe that defines all of the preprocessing steps necessary for the dataset.
  #
  # Arguments:
  #
  # trainX -- a tibble that represents the training dataset. Must include the target column as a factor variable labelled as "ResultProper".
  #
  # Returns:
  #
  # recipe
  #  A recipe object (a list) that defines the preprocessing pipeline.
  #
  ############################################################################################
  
  mainRecipe = recipe(ResultProper ~., data=trainX) %>%
    step_dummy(all_predictors(), -all_numeric()) %>%
    step_interact(terms = ~ SRS:Fenwick:ELORating) %>%
    step_interact(terms = ~ H2H:VegasOpeningOdds) %>%
    step_interact(terms = ~ FaceoffWinPercentage:ShotPercentage) %>%
    step_interact(terms = ~ contains("Round"):VegasOpeningOdds) %>%
    step_interact(terms = ~ SDRecord:SOS) %>%
    step_zv(all_predictors()) %>%
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    step_knnimpute(neighbors = 15, all_numeric(), all_predictors()) 
  
  mainRecipe
}

#.........................Define outer pipe for the outer cross validation fold...........................................#

modelPipe.outer = function(lambda.final, alpha.final, processedData, times){
  
  ############################################################################################
  # Fits a model on a training set, then validates the model using a specified set of hyperparameters (ideally found using the inner pipeline) on a held out test set. Works with function processFolds and is not intended to be used outside of this context.
  #
  # Arguments:
  #
  # lambda.final -- an integer value fed to each boostrapped elastic net model in the bag
  # alpha.final -- a numeric value in [0,1] used in fitting each bootstrapped elastic net model fit in the bag
  # processedData -- a named list that contains two tibbles: one tibble called "Train" and another tibble called "Test". Both of these tibbles should be the result of calling the function processFolds.
  # times -- an integer that provides how many bootstrapped models to fit in the bag
  # 
  # Returns:
  #
  # list
  #  A list containing the fitted models predictions, the fitted models log loss on the test set, and variable importance scores.
  #
  ############################################################################################
  
  
  train = processedData$Train
  test = processedData$Test
  
  model = baggedModel(train = train[, !names(train) %in% c("ResultProper")], test=test, label_train = train$ResultProper, 
                      alpha.a = alpha.final, s_lambda.a = lambda.final, times = times, calibrate = FALSE)
  
  #For AUROC
  #ROC = roc(response = test$ResultProper, predictor = model$Predictions, levels = c("L", "W"))$auc
  
  #For Log Loss
  
  logloss = logLoss(scores = model$Predictions, label = test$ResultProper)
  
  VarImp = model$VariableImportance
  
  list(Predictions = model$Predictions, LogLoss = logloss, VarImp = VarImp)
}
#.............................Process Folds...................................#

processFolds = function(fold.index, mainTrain, useOnlyVariables = NULL){
  
  ############################################################################################
  # Given a set of indices representing the training dataset (relative to the dataset mainTrain), process the training and implied testing datasets. 
  #
  # Arguments:
  #
  # fold.index -- a vector of indices corresponding to the training dataset (relative to mainTrain). 
  # mainTrain -- a tibble from which the training and testing sets will be derived from.
  # useOnlyVariables -- a character vector of column names in mainTrain from which the kNN variables should be computed. Default = NULL.
  #
  # Returns:
  #
  # list
  #  A named list containing the preprocessed training (Train) and test (Test) sets.
  #
  ############################################################################################
  
  train.param = prep(preProcess.recipe(trainX = mainTrain[fold.index,]), training = mainTrain[fold.index,])
  train = bake(train.param, new_data = mainTrain[fold.index,])
  test = bake(train.param, new_data = mainTrain[-fold.index,])
  
  frameswithPCA = addPCA_variables(traindata = train, testdata = test)
  
  train = frameswithPCA$train
  test = frameswithPCA$test
  
  rm(train.param, frameswithPCA)
  
  frameswithKNN = addKNN_variables(traindata = train, testdata = test, distances = TRUE, useOnlyVariables = useOnlyVariables)
  
  train = frameswithKNN$train
  test = frameswithKNN$test
  
  rm(frameswithKNN)
  
  list(Train = train, Test = test)
  
}


#..........................Processed variable importance output from the base model................................#
processVarImp = function(varImpRaw){
  
  ############################################################################################
  # Processes a list of variable importance scores generated by a bag of elastic net models. Uses simple averaging over all of the fitted models in the bag.
  #
  # Arguments:
  #
  # varImpRaw -- a list of tibbles that contain variable importance scores produced from the function baggedModel.
  #
  # Returns:
  #
  # tibble
  #  A tibble that contains the variable importance scores.
  #
  ############################################################################################
  
  varImpNames = varImpRaw %>% 
    select(., contains("Variable")) %>%
    .[,1]
  
  final = varImpRaw %>% 
    select(., contains("Importance")) %>%
    transmute(Importance = rowMeans(.)) %>%
    bind_cols(varImpNames, .)
  
  final
}

#..........................Ensemble-simple average with different seeds................................#
train.ensemble = function(folds, finalParameters, processedData, label_test, times){
  
  ############################################################################################
  # Trains an ensemble of bagged elastic nets. The ensemble is just a simple average over all fitted models trained on different seeds.
  #
  # Arguments:
  #
  # folds -- a list of indices corresponding to a train/test split of a dataset, generated from caret::createDataPartition
  # finalParameters -- a tibble with columns "lambda" and "alpha" used for fitting each bagged elastic net in the ensemble
  # processedData -- a named list that contains two tibbles: one tibble called "Train" and another tibble called "Test". Both of these tibbles should be the result of calling the function processFolds.
  # label_test -- a factor that provides the ground truth labels (Win = W or Loss = L) for the tibble labelled "Test" in processedData.
  # times -- number of bootstrapped models to fit in the bag
  #
  # Returns:
  #
  # list
  #  A list containing the log loss on the test set and the variable importance scores from the fitted model.
  #
  ############################################################################################
  
  finalPredictions = vector("list", nrow(finalParameters))
  finalVarImp = vector("list", nrow(finalParameters))
  
  for (k in 1:nrow(finalParameters)){
    
    finalModel = modelPipe.outer(lambda.final = as.integer(finalParameters$lambda[k]), alpha.final = finalParameters$alpha[k], times = times, processedData = processedData)
    
    finalPredictions[[k]] = finalModel$Predictions
    finalVarImp[[k]] = finalModel$VarImp
    
    rm(finalModel) 
    
  }
  
  if(nrow(finalParameters) > 1){
    
    finalPredictions.processed = finalPredictions %>% reduce(cbind) %>% rowMeans(.)
  
  } else {
    
    finalPredictions.processed = finalPredictions
    
  }
  
  finalVarImp.processed = finalVarImp %>% reduce(left_join, by = "Variable") %>% processVarImp(.)
  
  list(LogLoss = logLoss(scores = finalPredictions.processed, label = label_test), 
       VarImp = finalVarImp.processed)
  
}