#Dependencies
library(glmnet)
library(caret)
library(tidyverse)
library(recipes)
library(moments)
library(ParBayesianOptimization)
library(fastknn)
library(parallel)

#..................................Bagging Function...................................#
baggedModel = function(train, test, label_train, alpha.a, s_lambda.a, times, calibrate = FALSE){
  
  ############################################################################################
  # Generates a bagged (bootstrapped aggregated) elastic net model given a set of hyper parameters alpha and lambda.
  # 
  # Arguments:
  #
  # train -- a tibble containing the training data. The frame should contain only numeric values and be standardized and scaled. 
  # test -- a tibble containing the validation or test data that will be used to score the model's log loss. The frame should contain only numeric values and be standardized and scaled. 
  # label_train -- a factor ("ResultProper") corresponding to the train tibble.  
  # alpha.a -- a numeric value in [0,1] to train each elastic net model with in the bag.
  # s_lambda.a -- an integer value in {1, 2, 3, .... infinity} for subsetting the prediction matrix generated by glmnet. 
  # times -- an integer that specifies the number of bootstrap models to be created and then aggregated
  # calibrate -- a boolean: should the probabilities output by the trained model be calibrated? If TRUE, probabilities are calibrated using platt scaling. If FALSE, probabilities are left unprocessed. Default = TRUE.
  #
  #
  # Returns:
  #
  # list
  #   A list containing a tibble named "Predictions" which holds the predictions from the model on the test set, and another
  #   tibble containing variable importance scales generating during fitting.
  #
  ############################################################################################
  
  set.seed(3742301)
  samples = caret::createResample(y = label_train, times = times)
  pred = vector("list", length(samples))
  varImp = vector("list", length(samples))
  insample.pred = vector("list", length(samples))
  
  for (g in 1:length(samples)){
    
    train_temp = train[samples[[g]], ]
    train.label = label_train[samples[[g]]]
    modelX = glmnet(x = data.matrix(train_temp[, !names(train_temp) %in% c("ResultProper")]), y = train.label, family = "binomial", alpha = alpha.a, nlambda = 120, standardize = FALSE)
    s_lambda.a = case_when(s_lambda.a > length(modelX$lambda) ~ length(modelX$lambda), TRUE ~ s_lambda.a)
    
    pred[[g]] = predict(modelX, newx = data.matrix(test[, !names(test) %in% c("ResultProper")]), type = "response")[, s_lambda.a]
    insample.pred[[g]] = predict(modelX, newx = data.matrix(train_temp[, !names(train_temp) %in% c("ResultProper")]), type = "response")[, s_lambda.a]
    
    varImp[[g]] = tibble::rownames_to_column(varImp(modelX, lambda = modelX$lambda[s_lambda.a]), var = "Variable")
    colnames(varImp[[g]])[2] = paste("Overall:", g, sep = "")
    remove(modelX, train_temp, train.label)
    
  }
  
  pred = bind_cols(pred) %>%
    transmute(Predicted = rowMeans(.))
  
  insample.pred = bind_cols(insample.pred) %>%
    transmute(Predicted = rowMeans(.))
  
  varImp = varImp %>% reduce(left_join, by = "Variable") 
  
  means = varImp %>% select_if(is.numeric) %>% transmute(VariableImportance = rowMeans(.))
  
  varImp = tibble(Variable = varImp$Variable, meanImportance = means$VariableImportance)
  
  if(calibrate == TRUE){
    
    list(Predictions = platt.scale(label_train = label_train, predicted.prob.train = insample.pred, 
                                   predicted.prob.test = pred), VariableImportance = varImp)
    
  } else{
    
    list(Predictions = pred$Predicted, VariableImportance = varImp)  
    
  }
  
  
}

#..................................Platt Scaling/sigmoid........................................#
platt.scale = function(label_train, predicted.prob.train, predicted.prob.test){
  
  ############################################################################################
  # Calibrates a vector of probabilities using platt scaling.
  # 
  # Arguments:
  #
  # label_train -- a vector of labels (factors) for the training dataset
  # predicted.prob.train -- a numeric vector of probabilities generated on the training dataset 
  # predicted.prob.test -- a numeric vector of probabilities generated on the testing dataset
  #
  # Returns:
  #
  # numeric
  #   A vector of calibrated probabilities on the test set.
  #
  ############################################################################################
  
  model = glm(formula = label_train ~ ., data = predicted.prob.train, family = binomial(link = "logit"))
  
  scaled.prob = predict(model, newdata = predicted.prob.test, type = c("response"))
  
  scaled.prob
  
}

#..................................Log Loss Function....................................#

logLoss = function(scores, label){
  
  ############################################################################################
  # Computes the log loss given a set of probabilities and ground truth labels.
  # 
  # Arguments:
  #
  # scores -- a numeric vector of probabilities where the positive class is 1 and the negative class is 0. 
  # label -- a factor of W (win) or L (losses) representing the ground truth.
  # 
  #
  # Returns:
  #
  # numeric
  #  The mean log loss given the ground truth labels.
  #
  ############################################################################################
  
  if (is.factor(label)){
    u = ifelse(label ==  "W", 1,0)
  } else{
    u = label
  }
  
  tmp = data.frame(scores = scores, target = u)
  
  #In case there are probabilities of 1 or 0 predicted by the model (very unlikely unless severe overfitting)
  tmp = tmp %>% mutate(scores = ifelse(scores == 1, 0.9999999999999999999, ifelse(scores == 0 , 0.0000000000000000001, scores))) %>%
    mutate(logLoss = -(target * log(scores) + (1-target) * log(1-scores)))
  
  mean(tmp$logLoss)
}

#..................................PCA Function....................................#
addPCA_variables = function(traindata, testdata, standardize = FALSE){
  
  ############################################################################################
  # Binds PCA variables on to the training dataset (does not drop the columns used to create the PCA).
  # Does the same thing for the test set using the learned projection from the training set.
  # 
  # Arguments:
  #
  # traindata -- a tibble containing the training set. Should not contain the target variable (ResultProper) and if ResultProper is included, this variable will be removed before running the PCA. The tibble should only contain numeric values and be standardized and scaled. 
  # testdata -- a tibble containing the validation or test set. The tibble should only contain numeric values and be standardized and scaled.
  # standardize -- a boolean. If TRUE, standardizes and scales the resulting PCA components.
  #
  # Returns:
  #
  # list
  #  A list containing two tibbles corresponding to the original training and testing datasets with PCA variables included.
  #
  ############################################################################################
  
  traindata_tmp = traindata[, !names(traindata) %in% c("ResultProper")] %>% select_if(., is.numeric)
  testdata_tmp = testdata[, !names(testdata) %in% c("ResultProper")] %>% select_if(., is.numeric)
  
  pca_parameters = prcomp(traindata_tmp, center = FALSE, scale. = FALSE)
  pca_traindata = predict(pca_parameters, newdata = traindata_tmp)[,1:5] %>% as_tibble(.) 
  
  if(standardize == TRUE){
    
    pca_train.params = caret::preProcess(pca_traindata, method = c("center", "scale"))
    pca_traindata = predict(pca_train.params, newdata = pca_traindata)
    pca_newdata = predict(pca_parameters, newdata = testdata_tmp)[,1:5] %>% as_tibble(.) %>% predict(pca_train.params, newdata = .)
    
  }else{
    
    if(nrow(testdata) == 1){
      
      pca_newdata = predict(pca_parameters, newdata = testdata_tmp)[,1:5] %>% as_tibble(., rownames = "id") %>% spread(., key = "id", value = value)
      
    }else{
      
      pca_newdata = predict(pca_parameters, newdata = testdata_tmp)[,1:5] %>% as_tibble(.)
      
    }
  }
  
  
  list(train = bind_cols(traindata, pca_traindata), test = bind_cols(testdata, pca_newdata))
}

#..................................kNN Function....................................#
addKNN_variables = function(traindata, testdata, include_PCA = FALSE, distances = TRUE, useOnlyVariables =  NULL){
  
  ############################################################################################
  # Binds kNN variables to the dataset (does not delete the original variables used to create them)
  # Returns cumulative euclidian distances (sum of euclidian distances) to the k most closest neighbours for each class label to an observation, by default.
  # 
  # Arguments:
  #
  # traindata -- a tibble containing the training set. Should not contain the target variable (ResultProper) and if ResultProper is included, this variable will be removed before running the PCA. The tibble should only contain numeric values and be standardized and scaled. 
  # testdata -- a tibble containing the validation or test set. The tibble should only contain numeric values and be standardized and scaled.
  # include_PCA -- a boolean. If TRUE, includes any PCA components (see function addPCA_variables) in the creation of the kNN variables. Default = FALSE. The PCA variables should start with the prefix "PC".
  # distances -- a boolean. If TRUE, will return cumulative euclidian distances to the k most closest neighbours for each class label to an observation. If FALSE, calculates the proportion of winners (and therefore, losers) out of the k most closest neighbours to an observation.
  # useOnlyVariables -- a character vector that specifies which variables to use in traindata to compute kNN distances for. By default, uses all variables in traindata.
  #
  # Returns:
  #
  # list
  #  A list containing two tibbles corresponding to the original training and testing datasets with kNN variables included.
  #
  ############################################################################################
  
  if(!is.null(useOnlyVariables)){
    
    traindata_tmp = traindata %>% select(., useOnlyVariables)
    testdata_tmp = testdata %>% select(., useOnlyVariables)
    
  }
  
  if(include_PCA == TRUE){
    
    traindata_tmp = traindata %>% select_if(., is.numeric)
    testdata_tmp = testdata %>% select_if(., is.numeric)
    
  }else{
    
    traindata_tmp = traindata %>% select_if(., is.numeric) %>% as_tibble(.) %>% select(-starts_with("PC"))
    testdata_tmp = testdata %>% select_if(., is.numeric) %>% as_tibble(.) %>% select(-starts_with("PC"))
    
  }
  
  if (distances == TRUE){
    
    newframeswithKNN = fastknn::knnExtract(xtr = data.matrix(traindata_tmp), ytr = traindata$ResultProper, xte = data.matrix(testdata_tmp), k = 1, normalize = NULL)
    KNN_train = newframeswithKNN$new.tr %>% as_tibble(.) 
    
    KNN_train.params = caret::preProcess(KNN_train, method = c("center", "scale"))
    KNN_train = predict(KNN_train.params, newdata = KNN_train)
    
    KNN_test = newframeswithKNN$new.te %>% as_tibble(.) %>% predict(KNN_train.params, newdata = .)
    
    list(train = bind_cols(traindata, KNN_train), test = bind_cols(testdata, KNN_test))
    
  }else{
    
    KNN_train  = tibble(knn_W = fastknn(xtr = data.matrix(traindata_tmp), ytr = traindata$ResultProper, xte = data.matrix(traindata_tmp), k = 5, method = "vote", normalize = NULL)$prob[,2]) 
    
    KNN_train.params = caret::preProcess(KNN_train, method = c("center", "scale"))
    KNN_train = predict(KNN_train.params, newdata = KNN_train)
    
    KNN_test = tibble(knn_W = fastknn(xtr = data.matrix(traindata_tmp), ytr = traindata$ResultProper, xte = data.matrix(testdata_tmp), k = 5, method = "vote", normalize = NULL)$prob[,2]) %>%
      predict(KNN_train.params, newdata = .)
    
    list(train = bind_cols(traindata, KNN_train), test = bind_cols(testdata, KNN_test))
    
  }
  
}

#.......................Define recipe.............................................#

preProcess.recipe = function(trainX){
  
  ############################################################################################
  # Creates a recipe that defines all of the preprocessing steps necessary for the dataset.
  #
  # Arguments:
  #
  # trainX -- a tibble that represents the training dataset. Must include the target column as a factor variable labelled as "ResultProper".
  #
  # Returns:
  #
  # recipe
  #  A recipe object (a list) that defines the preprocessing pipeline.
  #
  ############################################################################################
  
  mainRecipe = recipe(ResultProper ~., data=trainX) %>%
    step_dummy(all_predictors(), -all_numeric()) %>%
    step_interact(terms = ~ SRS:Fenwick:ELORating) %>%
    step_interact(terms = ~ H2H:VegasOpeningOdds) %>%
    step_interact(terms = ~ FaceoffWinPercentage:ShotPercentage) %>%
    step_interact(terms = ~ contains("Round"):VegasOpeningOdds) %>%
    step_interact(terms = ~ SDRecord:SOS) %>%
    step_zv(all_predictors()) %>%
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    step_knnimpute(neighbors = 15, all_numeric(), all_predictors()) 
  
  mainRecipe
}

#.........................Define outer pipe for the outer cross validation fold...........................................#

modelPipe.outer = function(lambda.final, alpha.final, processedData, times){
  
  ############################################################################################
  # Fits a model on a training set, then validates the model using a specified set of hyperparameters (ideally found using the inner pipeline) on a held out test set. Works with function processFolds and is not intended to be used outside of this context.
  #
  # Arguments:
  #
  # lambda.final -- an integer value fed to each boostrapped elastic net model in the bag
  # alpha.final -- a numeric value in [0,1] used in fitting each bootstrapped elastic net model fit in the bag
  # processedData -- a named list that contains two tibbles: one tibble called "Train" and another tibble called "Test". Both of these tibbles should be the result of calling the function processFolds.
  # times -- an integer that provides how many bootstrapped models to fit in the bag
  # 
  # Returns:
  #
  # list
  #  A list containing the fitted models predictions, the fitted models log loss on the test set, and variable importance scores.
  #
  ############################################################################################
  
  
  train = processedData$Train
  test = processedData$Test
  
  model = baggedModel(train = train[, !names(train) %in% c("ResultProper")], test=test, label_train = train$ResultProper, 
                      alpha.a = alpha.final, s_lambda.a = lambda.final, times = times, calibrate = FALSE)
  
  #For AUROC
  #ROC = roc(response = test$ResultProper, predictor = model$Predictions, levels = c("L", "W"))$auc
  
  #For Log Loss
  
  logloss = logLoss(scores = model$Predictions, label = test$ResultProper)
  
  VarImp = model$VariableImportance
  
  list(Predictions = model$Predictions, LogLoss = logloss, VarImp = VarImp)
}
#.............................Process Folds...................................#

processFolds = function(fold.index, mainTrain, useOnlyVariables = NULL){
  
  ############################################################################################
  # Given a set of indices representing the training dataset (relative to the dataset mainTrain), process the training and implied testing datasets. 
  #
  # Arguments:
  #
  # fold.index -- a vector of indices corresponding to the training dataset (relative to mainTrain). 
  # mainTrain -- a tibble from which the training and testing sets will be derived from.
  # useOnlyVariables -- a character vector of column names in mainTrain from which the kNN variables should be computed. Default = NULL.
  #
  # Returns:
  #
  # list
  #  A named list containing the preprocessed training (Train) and test (Test) sets.
  #
  ############################################################################################
  
  train.param = prep(preProcess.recipe(trainX = mainTrain[fold.index,]), training = mainTrain[fold.index,])
  train = bake(train.param, new_data = mainTrain[fold.index,])
  test = bake(train.param, new_data = mainTrain[-fold.index,])
  
  frameswithPCA = addPCA_variables(traindata = train, testdata = test)
  
  train = frameswithPCA$train
  test = frameswithPCA$test
  
  rm(train.param, frameswithPCA)
  
  frameswithKNN = addKNN_variables(traindata = train, testdata = test, distances = TRUE, useOnlyVariables = useOnlyVariables)
  
  train = frameswithKNN$train
  test = frameswithKNN$test
  
  rm(frameswithKNN)
  
  list(Train = train, Test = test)
  
}

#..........................Processed variable importance output from the base model................................#
processVarImp = function(varImpRaw){
  
  ############################################################################################
  # Processes a list of variable importance scores generated by a bag of elastic net models. Uses simple averaging over all of the fitted models in the bag.
  #
  # Arguments:
  #
  # varImpRaw -- a list of tibbles that contain variable importance scores produced from the function baggedModel.
  #
  # Returns:
  #
  # tibble
  #  A tibble that contains the variable importance scores.
  #
  ############################################################################################
  
  varImpNames = varImpRaw %>% 
    select(., contains("Variable")) %>%
    .[,1]
  
  final = varImpRaw %>% 
    select(., contains("Importance")) %>%
    transmute(Importance = rowMeans(.)) %>%
    bind_cols(varImpNames, .)
  
  final
}

#..........................RFE Selection......................................#

rfeSelection = function(allProcessedFrames, subset.size, varImp){
  
  ############################################################################################
  # Trains a model with a reduced subset of features as given by subset.size.
  #
  # Arguments:
  #
  # allProcessedFrames -- a list that has two named tibbles; Train and Test. Should be the result of the the function processFolds.
  # subset.size -- an integer value that takes the top (subset.size) number of features, as given in the varImp argument
  # varImp -- a tibble that has two columns: Variable, which gives the variable name corresponding to a column in any of the tibbles in allProcessedFrames, and Importance, which provides the variable importance from the bagged elastic net using all features.
  #
  # Returns:
  #
  # tibble
  #  A tibble that provides the most optimal alpha and lambda for a given subset size.
  #
  ############################################################################################
  varImp.sorted = varImp %>% arrange(-Importance) %>% .[1:subset.size,] %>% select(Variable) 
  
  bestParam = BayesianOptimization(FUN =  function(alpha, lambda){
    
    scores = vector("numeric", length(allProcessedFrames))
    varImp = vector("list", length(allProcessedFrames))
    
    for(m in 1:length(allProcessedFrames)){
      
      Train = allProcessedFrames[[m]]$Train %>% select(varImp.sorted$Variable, ResultProper)
      Test = allProcessedFrames[[m]]$Test %>% select(varImp.sorted$Variable, ResultProper)
      
      model = baggedModel(train = Train, test = Test, label_train = Train$ResultProper, alpha = alpha, s_lambda.a = as.integer(lambda), calibrate = FALSE)
      scores[m] = logLoss(scores = model$Predictions, label = Test$ResultProper)
      varImp[[m]] = model$VariableImportance
      
    }
    
    list(Score = -mean(scores))
    
  }
  , bounds = list(alpha = c(0, 1), lambda = c(15L, 90L)),
  initPoints = 3, nIters = 45, convThresh = 1e+02, verbose = 0)
  
  tibble(Subset.Size = subset.size, alpha = bestParam$ScoreDT$alpha[which.max(bestParam$ScoreDT$Score)], lambda = as.integer(bestParam$ScoreDT$lambda[which.max(bestParam$ScoreDT$Score)]))
  
}