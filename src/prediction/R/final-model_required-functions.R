library(tidyverse)
library(glmnet)
library(recipes)
library(caret)
library(parallel)
library(fastknn)
library(ParBayesianOptimization)

#..................................Bagging Function...................................#
bagged_model <- function(train, test, label_train, alpha, s_lambda, times, calibrate = FALSE) {
  
  #' Generates a bagged (bootstrapped aggregated) elastic net model given a set of hyper parameters alpha and lambda.
  #'
  #' @param train a tibble containing the training data. The frame should contain only numeric values and be standardized and scaled. 
  #' @param test a tibble containing the validation or test data that will be used to score the model's log loss. The frame should contain only numeric values and be standardized and scaled. 
  #' @param label_train a factor ("ResultProper") corresponding to the train tibble.  
  #' @param alpha_a a numeric value in [0,1] to train each elastic net model with in the bag.
  #' @param s_lambda_a an integer value in {1, 2, 3, .... infinity} for subsetting the prediction matrix generated by glmnet. 
  #' @param times an integer that specifies the number of bootstrap models to be created and then aggregated
  #' @param calibrate a logical: should the probabilities output by the trained model be calibrated? If TRUE, probabilities are calibrated using platt scaling. If FALSE, probabilities are left unprocessed. Default = TRUE.
  #'
  #' @return 
  #' A list containing a tibble named "Predictions" which holds the predictions from the model on the test set, and another
  #' tibble containing variable importance scales generating during fitting.
  #'
  #' @export
  #'
  
  set.seed(3742301)
  samples <- caret::createResample(y = label_train, times = times)
  pred <- vector("list", length(samples))
  var_imp <- vector("list", length(samples))
  insample_pred <- vector("list", length(samples))
  
  for (g in 1:length(samples)) {
    
    train_temp <- train[samples[[g]], ]
    train_label <- label_train[samples[[g]]]
    model_x <- glmnet(x = data.matrix(train_temp[, !names(train_temp) %in% c("result_factor")]), y = train_label, family = "binomial", alpha = alpha, nlambda = 120, standardize = FALSE)
    s_lambda <- case_when(s_lambda > length(model_x$lambda) ~ length(model_x$lambda), TRUE ~ s_lambda)
    
    pred[[g]] <- predict(model_x, newx = data.matrix(test[, !names(test) %in% c("result_factor")]), type = "response")[, s_lambda]
    insample_pred[[g]] <- predict(model_x, newx = data.matrix(train_temp[, !names(train_temp) %in% c("result_factor")]), type = "response")[, s_lambda]
    
    var_imp[[g]] <- tibble::rownames_to_column(caret::varImp(model_x, lambda = model_x$lambda[s_lambda]), var = "variable")
    colnames(var_imp[[g]])[2] <- paste("Overall:", g, sep = "")
    remove(model_x, train_temp, train_label)
    
  }
  
  pred <- bind_cols(pred) %>%
    transmute(predicted = rowMeans(.))
  
  insample_pred <- bind_cols(insample_pred) %>%
    transmute(predicted = rowMeans(.))
  
  var_imp <- var_imp %>% reduce(left_join, by = "variable") 
  
  means <- var_imp %>% 
    select_if(is.numeric) %>%
    transmute(variable_importance = rowMeans(.))
  
  var_imp <- tibble(Variable = var_imp$variable, mean_importance = means$variable_importance)
  
  if (calibrate == TRUE) {
    list(predictions = platt_scale(label_train = label_train, predicted_prob_train = insample_pred, 
                                   predicted_prob_test = pred), variable_importance = var_imp)
  } else {
    list(predictions = pred$predicted, variable_importance = var_imp)  
  }
}


#..................................Platt Scaling/sigmoid........................................#
platt_scale <- function(label_train, predicted_prob_train, predicted_prob_test) {
  
  #' Calibrates a vector of probabilities using platt scaling.
  #' 
  #' @param label_train a vector of labels (factors) for the training dataset
  #' @param predicted_prob_train  a numeric vector of probabilities generated on the training dataset 
  #' @param predicted_prob_test a numeric vector of probabilities generated on the testing dataset
  #'
  #' @return 
  #' A numeric vector containing calibrated probabilities on the test set.
  #'
  #' @export
  #'
  
  model <- glm(formula = label_train ~ ., data = predicted_prob_train, family = binomial(link = "logit"))
  
  predict(model, newdata = predicted_prob_test, type = c("response"))
  
}

#..................................Log Loss Function....................................#

log_loss <- function(scores, label) {
  
  #' Computes the log loss given a set of probabilities and ground truth labels.
  #' 
  #' Arguments:
  #'
  #' @param scores a numeric vector of probabilities where the positive class is 1 and the negative class is 0. 
  #' @param label a factor of W (win) or L (losses) representing the ground truth.
  #' 
  #' @return
  #' A vector of length one containing the mean log loss given the ground truth labels.
  #'
  #' @export
  #' 
  
  if (is.factor(label)) {
    u <- ifelse(label ==  "W", 1,0)
  } else {
    u <- label
  }
  
  tmp <- data.frame(scores = scores, target = u)
  
  #In case there are probabilities of 1 or 0 predicted by the model (very unlikely unless severe overfitting)
  tmp <- tmp %>%
    mutate(scores = ifelse(scores == 1, 0.9999999999999999999, ifelse(scores == 0 , 0.0000000000000000001, scores))) %>%
    mutate(log_loss = -(target * log(scores) + (1 - target) * log(1 - scores)))
  
  mean(tmp$log_loss)
}

#..................................PCA Function....................................#
add_pca_variables <- function(train_data, test_data, ncomp = 5L, standardize = FALSE) {
  
  #' Binds PCA variables on to the training dataset (does not drop the columns used to create the PCA).
  #'   Does the same thing for the test set using the learned projection from the training set.
  #' 
  #' @param train_data a tibble containing the training set. Should not contain the target variable (ResultProper) and if ResultProper is included, this variable will be removed before running the PCA. The tibble should only contain numeric values and be standardized and scaled. 
  #' @param test_data a tibble containing the validation or test set. The tibble should only contain numeric values and be standardized and scaled.
  #' @param standardize a boolean. If TRUE, standardizes and scales the resulting PCA components.
  #'
  #' @return
  #' A list containing two tibbles corresponding to the original training and testing datasets with PCA variables included.
  #'
  #' @export 
  #'
  
  train_data_tmp <- train_data[, !names(train_data) %in% c("result_factor")] %>% select_if(., is.numeric)
  test_data_tmp <- test_data[, !names(test_data) %in% c("result_factor")] %>% select_if(., is.numeric)
  
  pca_parameters <- prcomp(train_data_tmp, center = FALSE, scale. = FALSE)
  pca_train_data <- predict(pca_parameters, newdata = train_data_tmp)[, 1:ncomp] %>% as_tibble(.) 
  
  if (standardize == TRUE) {
    pca_train_params <- caret::preProcess(pca_train_data, method = c("center", "scale"))
    pca_train_data <- predict(pca_train_params, newdata = pca_train_data)
    
    pca_new_data <- predict(pca_parameters, newdata = test_data_tmp)[,1:ncomp] %>%
      as_tibble(.) %>% 
      predict(pca_train_params, newdata = .)
  } else {
    
    if (nrow(test_data) == 1) {
      pca_newdata <- predict(pca_parameters, newdata = test_data_tmp)[, 1:ncomp] %>%
        as_tibble(., rownames = "id") %>% 
        spread(., key = "id", value = value)
    } else {
      pca_newdata <- predict(pca_parameters, newdata = test_data_tmp)[,1:ncomp] %>% 
        as_tibble(.)
    }
  }
  list(
    train = bind_cols(train_data, pca_train_data) %>% set_names(~str_to_lower(.)), 
    test = bind_cols(test_data, pca_newdata) %>% set_names(~str_to_lower(.)))
}

add_knn_variables <- function(train_data, test_data, include_PCA = FALSE, distances = TRUE, use_only_variables =  NULL) {
  
  #' Binds kNN variables to the dataset (does not delete the original variables used to create them)
  #' Returns cumulative euclidian distances (sum of euclidian distances) to the k most closest neighbours for each class label to an observation, by default.
  #' 
  #' @param traindata a tibble containing the training set. Should not contain the target variable (ResultProper) and if ResultProper is included, this variable will be removed before running the PCA. The tibble should only contain numeric values and be standardized and scaled. 
  #' @param testdata a tibble containing the validation or test set. The tibble should only contain numeric values and be standardized and scaled.
  #' @param include_PCA a logical. If TRUE, includes any PCA components (see function addPCA_variables) in the creation of the kNN variables. Default = FALSE. The PCA variables should start with the prefix "PC".
  #' @param distances a logial. If TRUE, will return cumulative euclidian distances to the k most closest neighbours for each class label to an observation. If FALSE, calculates the proportion of winners (and therefore, losers as well) out of the k most closest neighbours to an observation.
  #' @param useOnlyVariables a character vector that specifies which variables to use in traindata to compute kNN distances for. By default, uses all variables in traindata.
  #'
  #' @return
  #' A list containing two tibbles corresponding to the original training and testing datasets with kNN variables included.
  #'
  #' @export
  #'
  
  if (!is.null(use_only_variables)) {
    train_data_tmp <- train_data %>% select(., use_only_variables)
    test_data_tmp <- test_data %>% select(., use_only_variables)
  }
  
  if (include_PCA == TRUE) {
    train_data_tmp <- train_data %>% select_if(., is.numeric)
    test_data_tmp <- test_data %>% select_if(., is.numeric)
  } else {
    train_data_tmp <- train_data %>% select_if(., is.numeric) %>% as_tibble(.) %>% select(-starts_with("pc"))
    test_data_tmp <- test_data %>% select_if(., is.numeric) %>% as_tibble(.) %>% select(-starts_with("pc"))
  }
  
  if (distances == TRUE) {
    new_frames_with_knn <- fastknn::knnExtract(
      xtr = data.matrix(train_data_tmp), 
      ytr = train_data$result_factor,
      xte = data.matrix(test_data_tmp),
      k = 1,
      normalize = NULL)
    
    knn_train <- new_frames_with_knn$new.tr %>% as_tibble(.) 
    
    knn_train_params <- caret::preProcess(knn_train, method = c("center", "scale"))
    knn_train <- predict(knn_train_params, newdata = knn_train)
    
    knn_test <- new_frames_with_knn$new.te %>% as_tibble(.) %>% predict(knn_train_params, newdata = .)
    
    list(
      train = bind_cols(train_data, knn_train) %>% set_names(~str_to_lower(.)),
      test = bind_cols(test_data, knn_test) %>% set_names(~str_to_lower(.)))
    
  } else {
    
    knn_train <- tibble(knn_W = fastknn(
      xtr = data.matrix(train_data_tmp),
      ytr = train_data$result_factor,
      xte = data.matrix(train_data_tmp),
      k = 5, 
      method = "vote", 
      normalize = NULL)$prob[,2]) 
    
    knn_train_params <- caret::preProcess(knn_train, method = c("center", "scale"))
    knn_train <- predict(knn_train_params, newdata = knn_train)
    
    knn_test <- tibble(knn_w = fastknn(
      xtr = data.matrix(train_data_tmp), 
      ytr = train_data$result_factor, 
      xte = data.matrix(test_data_tmp), 
      k = 5, 
      method = "vote", 
      normalize = NULL)$prob[,2]) %>%
      predict(knn_train_params, newdata = .)
    
    list(train = bind_cols(train_data, knn_train) %>% set_names(~str_to_lower(.)),
         test = bind_cols(test_data, knn_test) %>% set_names(~str_to_lower(.)))
  }
}

#.......................Define recipe.............................................#

pre_process_recipe <- function(trainX) {
  
  #' Creates a recipe that defines all of the preprocessing steps necessary for the dataset.
  #'
  #' @param trainX a tibble that represents the training dataset. Must include the target column as a factor variable labelled as "ResultProper".
  #'
  #' @return
  #' A recipe object (a list) that defines the preprocessing pipeline.
  #'
  #' @export
  #'
  
  main_recipe <- recipe(result_factor ~., data = trainX) %>%
    step_dummy(all_predictors(), -all_numeric()) %>%
    step_interact(terms = ~ srs:fenwick:elo_rating) %>%
    step_interact(terms = ~ h2h:vegas_odds) %>%
    step_interact(terms = ~ faceoff_win_percentage:shot_percentage) %>%
    step_interact(terms = ~ contains("round"):vegas_odds) %>%
    step_interact(terms = ~ sd_record:sos) %>%
    step_zv(all_predictors()) %>%
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    step_knnimpute(neighbors = 15, all_numeric(), all_predictors()) 
  
  main_recipe
}

#.............................Process Folds...................................#

process_folds <- function(fold_index, main_train, use_only_variables = NULL) {
  
  #' Given a set of indices representing the training dataset (relative to the dataset mainTrain), process the training and implied testing datasets. 
  #'
  #' @param fold.index a vector of indices corresponding to the training dataset (relative to mainTrain). 
  #' @param mainTrain a tibble from which the training and testing sets will be derived from.
  #' @param useOnlyVariables a character vector of column names in mainTrain from which the kNN variables should be computed. Default = NULL.
  #'
  #' @return
  #' A named list containing the preprocessed training (Train) and test (Test) sets.
  #'
  #' @export
  #'
  
  train_param <- prep(pre_process_recipe(trainX = main_train[fold_index, ]), training = main_train[fold_index, ])
  train <- bake(train_param, new_data = main_train[fold_index, ])
  test <- bake(train_param, new_data = main_train[-fold_index, ])
  
  frames_with_pca <- add_pca_variables(train_data = train, test_data = test)
  
  train <- frames_with_pca$train
  test <- frames_with_pca$test
  
  rm(train_param, frames_with_pca)
  
  frames_with_knn <- add_knn_variables(train_data = train, test_data = test, distances = TRUE, use_only_variables = use_only_variables)
  
  train <- frames_with_knn$train
  test <- frames_with_knn$test
  
  rm(frames_with_knn)
  
  list(train = train, test = test)
  
}

#..........................Processed variable importance output from the base model................................#
process_var_imp <- function(var_imp_raw) {
  
  #' Processes a list of variable importance scores generated by a bag of elastic net models. Uses simple averaging over all of the fitted models in the bag.
  #'
  #' @param varImpRaw a list of tibbles that contain variable importance scores produced from the function baggedModel.
  #'
  #' @return 
  #' A tibble that contains the variable importance scores.
  #'
  #' @export
  #'
  
  var_imp_names <- var_imp_raw %>% 
    select(., contains("variable")) %>%
    .[,1]
  
  final <- var_imp_raw %>% 
    select(., contains("importance")) %>%
    transmute(importance = rowMeans(.)) %>%
    bind_cols(var_imp_names, .)
  
  final
}

#.........................The main inner pipe....................................#

train_model_one_rep <- function(rep_index, inner_folds, main_train, times = 20, n_iters = 25) {

  repetition_folds <- inner_folds[str_detect(string = names(inner_folds), pattern = paste("rep", rep_index, sep = ""))]
  all_processed_frames <- map_df(repetition_folds, process_folds, main_train = main_train)
  
  best_param <- BayesianOptimization(FUN =  function(alpha, lambda) {
      
      scores <- vector("numeric", length(all_processed_frames))

      for (m in 1:length(all_processed_frames)) {
        
        model <- bagged_model(
          train = all_processed_frames[[m]]$train,
          test = all_processed_frames[[m]]$test, 
          label_train = all_processed_frames[[m]]$train$result_factor,
          alpha = alpha, 
          times = times,
          s_lambda = as.integer(lambda),
          calibrate = FALSE)
        
        scores[m] = log_loss(
          scores = model$predictions, 
          label = all_processed_frames[[m]]$test$result_proper)
        
      }
      

      list(Score = -mean(scores))
      
    }
    , bounds = list(alpha = c(0, 1), lambda = c(15L, 90L)),
    initPoints = 3, nIters = n_iters)
    
    tibble(alpha = best_param$Best_Par[1], lambda = as.integer(best_param$Best_Par[2]))
  
}
  

